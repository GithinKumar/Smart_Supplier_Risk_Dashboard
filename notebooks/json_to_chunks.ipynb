{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f7a125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Quarterly financial metrics for each supplier, including credit score, revenue, and D&B rating. ML Model 'Isolation Forest' (Unsupervised anomaly detection, library: scikit-learn) is used for: Calculate financial risk scores for suppliers based on anomaly detection in their financial data. Features used: Credit Score, Revenue (USD), D&B Rating. Output: Financial Risk Score (0-100), higher means higher anomaly risk. Columns: Supplier ID, Quarter, Credit Score, Revenue (USD), D&B Rating. Parameters: contamination=0.1; random_state=42. Reason: Isolation Forest is well-suited for identifying anomalies in high-dimensional, unlabeled data such as supplier financial metrics. It efficiently detects outliers without requiring labeled examples of risky suppliers, making it ideal for unsupervised financial risk detection in this context..\n",
      "- Calculates a comprehensive supplier performance score each quarter by combining operational performance data, financial risk, and supplier tier using a supervised machine learning approach. ML Model 'XGBRegressor' (Supervised regression, library: xgboost) is used for: To predict an overall supplier score based on a mix of operational, financial, and categorical supplier features. Features used: %_on_time, %_delayed, avg_delay, avg_shipment_volume, %_shipment_lost, %_defect_rate, Financial Risk Score, Tier, delay_defect_interaction, volume_delay_interaction, volume_lost_interaction, defect_lost_interaction, log_avg_delay, log_shipment_volume. Output: . Columns: Supplier ID, Quarter, %_on_time, %_delayed, avg_delay, avg_shipment_volume, %_shipment_lost, %_defect_rate, Financial Risk Score, Tier, delay_defect_interaction, volume_delay_interaction, volume_lost_interaction, defect_lost_interaction, log_avg_delay, log_shipment_volume, Supplier Score. Parameters: random_state=42. Reason: XGBoost (XGBRegressor) was chosen for its high performance, ability to handle both linear and non-linear relationships, support for feature interactions, and robustness with tabular data. It also provides built-in handling of missing values and is widely used for structured regression tasks..\n",
      "- Training details for model 'XGBRegressor': train/test split: 80% train, 20% test, scaling: StandardScaler used for feature normalization.\n",
      "- Supplier SUP001: Nortech Electronics, Region: North America, Tier: Tier 1.\n",
      "- Supplier SUP002: EuroAuto Parts, Region: Europe, Tier: Tier 2.\n",
      "- Supplier SUP003: AsiaText Co, Region: Asia, Tier: Tier 1.\n",
      "- Supplier SUP004: ChemSouth Ltd, Region: South America, Tier: Tier 3.\n",
      "- Supplier SUP005: AfriMine Corp, Region: Africa, Tier: Tier 2.\n",
      "- Supplier SUP006: GlobalMed Supply, Region: Global, Tier: Tier 1.\n",
      "- Supplier SUP001 had an average performance score of 84.33 from 2020 to 2023.\n",
      "- Supplier SUP002 had an average performance score of 77.456 from 2020 to 2023.\n",
      "- Supplier SUP003 had an average performance score of 83.75 from 2020 to 2023.\n",
      "- Supplier SUP004 had an average performance score of 81.93 from 2020 to 2023.\n",
      "- Supplier SUP005 had an average performance score of 75.0 from 2020 to 2023.\n",
      "- Supplier SUP006 had an average performance score of 83.19 from 2020 to 2023.\n",
      "- Flagged suppliers: SUP003, SUP005\n",
      "- Supplier SUP003: AsiaText Co (Flagged in 2021-Q3)\n",
      "- Supplier SUP005: AfriMine Corp (Flagged in 2021-Q4, 2023-Q2)\n",
      "- Chart 'Average Supplier Score' (Bar Chart): Displays the average risk score for each supplier, highlighting those with risk scores above the threshold. X-axis: Supplier ID, Y-axis: Supplier Score. Filters: Value Category, Date Range. Source data: Supplier_score_final. Highlighted: Flagged suppliers.\n",
      "- Chart 'Total Shipment Volume per supplier' (Bar Chart): Displays the total shipment volume for each supplier as per the date range and value category selected. X-axis: Supplier ID, Y-axis: Total Shipment Volume. Filters: Value Category, Date Range. Source data: supplier_delivery_dataset.\n",
      "\n",
      "Total chunks: 141\n",
      "Chunks saved to ../Data/all_metadata_chunks.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Set paths (adjust if your folder is different)\n",
    "dashboard_metadata_path = Path(\"../Data/dashboard_metadata.json\")\n",
    "supplier_delivery_metadata_path = Path(\"../Data/supplier_delivery_metadata.json\")\n",
    "\n",
    "# Load the JSONs\n",
    "with open(dashboard_metadata_path, \"r\") as f:\n",
    "    dashboard = json.load(f)\n",
    "with open(supplier_delivery_metadata_path, \"r\") as f:\n",
    "    deliveries = json.load(f)\n",
    "\n",
    "chunks = []\n",
    "\n",
    "# ----- Dashboard metadata -----\n",
    "\n",
    "# --- ML Models (Financial + Supplier Score) ---\n",
    "for ml_key in [\"ML_financial\", \"ML_Supplier_score\"]:\n",
    "    ml = dashboard.get(ml_key, {})\n",
    "    if ml:\n",
    "        desc = ml.get(\"description\", \"\")\n",
    "        columns = \", \".join(ml.get(\"columns\", []))\n",
    "        model_info = ml.get(\"ml_model\", {})\n",
    "        purpose = model_info.get(\"purpose\", \"\")\n",
    "        name = model_info.get(\"name\", \"\")\n",
    "        mtype = model_info.get(\"type\", \"\")\n",
    "        lib = model_info.get(\"library\", \"\")\n",
    "        features = \", \".join(model_info.get(\"features_used\", []))\n",
    "        output = model_info.get(\"output\", \"\")\n",
    "        why = model_info.get(\"why_this_model\", \"\")\n",
    "        parameters = \"; \".join([f\"{k}={v}\" for k, v in model_info.get(\"parameters\", {}).items()])\n",
    "        chunk = (\n",
    "            f\"ML Model '{name}' ({mtype}, library: {lib}) is used for: {purpose} \"\n",
    "            f\"Features used: {features}. Output: {output}. Columns: {columns}. \"\n",
    "            f\"Parameters: {parameters}. Reason: {why}.\"\n",
    "        )\n",
    "        if desc:\n",
    "            chunk = f\"{desc} \" + chunk\n",
    "        chunks.append(chunk)\n",
    "\n",
    "        # Add training details (if any)\n",
    "        training = model_info.get(\"training\", {})\n",
    "        if training:\n",
    "            chunks.append(\n",
    "                f\"Training details for model '{name}': train/test split: {training.get('train_test_split', '')}, \"\n",
    "                f\"scaling: {training.get('scaling', '')}.\"\n",
    "            )\n",
    "\n",
    "# --- Supplier Master Data ---\n",
    "suppliers = dashboard.get(\"supplier_master_data\", {})\n",
    "for sid, entry in suppliers.items():\n",
    "    chunks.append(\n",
    "        f\"Supplier {entry['Supplier ID']}: {entry['Supplier Name']}, Region: {entry['Region']}, Tier: {entry['Tier']}.\"\n",
    "    )\n",
    "\n",
    "# --- Average Supplier Scores ---\n",
    "for sid, score in dashboard.get(\"average_supplier_score_2020_2023\", {}).items():\n",
    "    chunks.append(\n",
    "        f\"Supplier {sid} had an average performance score of {score} from 2020 to 2023.\"\n",
    "    )\n",
    "\n",
    "# --- Flagged Suppliers ---\n",
    "flagged = dashboard.get(\"Flagged_suppliers\", {})\n",
    "if flagged:\n",
    "    chunks.append(f\"Flagged suppliers: {flagged.get('suppliers flagged', 'N/A')}\")\n",
    "    # Add per-supplier flag details (humanized)\n",
    "    if flagged.get(\"SUP003_Flagged_quarters\"):\n",
    "        chunks.append(f\"Supplier SUP003: {flagged['SUP003_Flagged_quarters']}\")\n",
    "    if flagged.get(\"SUP005_Flagged_quarters\"):\n",
    "        chunks.append(f\"Supplier SUP005: {flagged['SUP005_Flagged_quarters']}\")\n",
    "\n",
    "# --- Charts ---\n",
    "for chart in dashboard.get(\"charts\", []):\n",
    "    # Human readable description for each chart\n",
    "    c_desc = (\n",
    "        f\"Chart '{chart['title']}' ({chart['type']}): {chart['description']} \"\n",
    "        f\"X-axis: {chart.get('x_axis', '')}, Y-axis: {chart.get('y_axis', '')}. \"\n",
    "        f\"Filters: {', '.join(chart.get('filters', []))}. Source data: {chart.get('source_data', '')}.\"\n",
    "    )\n",
    "    if \"highlighted\" in chart:\n",
    "        c_desc += f\" Highlighted: {chart['highlighted']}.\"\n",
    "    if \"highlighted_events\" in chart:\n",
    "        c_desc += f\" Highlighted events: {', '.join(chart['highlighted_events'])}.\"\n",
    "    if \"purpose\" in chart:\n",
    "        c_desc += f\" Purpose: {chart['purpose']}.\"\n",
    "    chunks.append(c_desc)\n",
    "\n",
    "# --- LLM Model Details (for reference) ---\n",
    "llm = dashboard.get(\"llm_model\", {})\n",
    "if llm:\n",
    "    llm_chunk = (\n",
    "        f\"LLM Model: {llm.get('name', '')} by {llm.get('provider', '')}. \"\n",
    "        f\"Purpose: {llm.get('purpose', '')}. Limitations: {', '.join(llm.get('limitations', []))}\"\n",
    "    )\n",
    "    chunks.append(llm_chunk)\n",
    "\n",
    "# ----- Delivery metadata -----\n",
    "for row in deliveries.get(\"filtered_supplier_deliveries\", []):\n",
    "    s_id = row.get(\"Supplier ID\", \"Unknown\")\n",
    "    order = row.get(\"Order Date\", \"\")\n",
    "    expected = row.get(\"Expected Delivery Date\", \"\")\n",
    "    actual = row.get(\"Actual Delivery Date\", \"\")\n",
    "    lost = row.get(\"Shipment Lost\", False)\n",
    "    defected = row.get(\"Defected\", False)\n",
    "    volume = row.get(\"Shipment Volume\", \"\")\n",
    "    value = row.get(\"Value Category\", \"\")\n",
    "    \n",
    "    # Start chunk with delivery fact\n",
    "    text = (\n",
    "        f\"Supplier {s_id} shipment ordered on {order}: \"\n",
    "        f\"Expected delivery {expected}, Actual delivery {actual}. \"\n",
    "        f\"Shipment volume: {volume}, Value category: {value}.\"\n",
    "    )\n",
    "    \n",
    "    # Add status\n",
    "    if lost and defected:\n",
    "        text += \" This shipment was LOST and DEFECTED.\"\n",
    "    elif lost:\n",
    "        text += \" This shipment was LOST.\"\n",
    "    elif defected:\n",
    "        text += \" This shipment was DEFECTED.\"\n",
    "    else:\n",
    "        text += \" This shipment was delivered without loss or defect.\"\n",
    "    \n",
    "    chunks.append(text)\n",
    "\n",
    "# Print a few example chunks\n",
    "for c in chunks[:20]:\n",
    "    print(\"-\", c)\n",
    "print(f\"\\nTotal chunks: {len(chunks)}\")\n",
    "\n",
    "# Save the chunks to a text file\n",
    "with open(\"../Data/all_metadata_chunks.txt\", \"w\") as out:\n",
    "    for chunk in chunks:\n",
    "        out.write(chunk + \"\\n\")\n",
    "print(\"Chunks saved to ../Data/all_metadata_chunks.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
